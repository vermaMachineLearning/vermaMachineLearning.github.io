<!DOCTYPE html>
<html>
  <head>
    <!-- Saurabh Verma 2016 UMN <https://github.com/vermaMachineLearning> -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="utf-8">
    
    <meta name="description" content="Blog: Machine Learning Equations by Saurabh Verma">
    <title>  Blog: Why Regularized Auto-Encoders learn Sparse Representation? › Blog: Machine Learning Equations by Saurabh Verma</title>
    <link rel="canonical" href="http://localhost:4000/paperlist/2016/05/31/why-autoencoder-sparse.html">
    <link href="/main.css" rel="stylesheet" type="text/css">
    <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,200italic,300italic,400italic,600italic,700italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Gentium+Basic:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css' rel='stylesheet' type='text/css'>
    <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Blog: Machine Learning Equations by Saurabh Verma" />
    <script src="//saurabhML.disqus.com/embed.js" async></script>
    
	
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-78615814-1', 'auto');
  ga('send', 'pageview');

</script>

  </head>
  <body>
    <header>
      <h1><a href="/">Blog: Machine Learning Equations by Saurabh Verma</a></h1>
      <nav>
        <ul>
          <li><a href="/">Home</a></li><li><a href="/about.html">About</a></li><li><a href="/archive.html">Archive</a></li>
        </ul>
      </nav>
    </header>
    
    
    <article>
      <header>
        <h2><a href="/paperlist/2016/05/31/why-autoencoder-sparse.html"> Blog: Why Regularized Auto-Encoders learn Sparse Representation?</a></h2>
        <p><time datetime="2016-05-31T17:37:00-05:00">May 31, 2016</time> • PaperList</p>
      </header>
      <div>
<p>This paper has some great insights to offer in design of autoencoders. As title suggests, it addresses “whether regularized helps in learning sparse representation of the data theoretically?”</p>

<p><strong>Here is the setup:</strong> we have an input <script type="math/tex">\mathbf{x} \in \mathbf{R}^{d}</script> which is mapped to latent space <script type="math/tex">\mathbf{h=s(Wx+b)}</script> via autoencoder where <script type="math/tex">\mathbf{s}</script> is encoder activation function, <script type="math/tex">\mathbf{W} \in \mathbf{R}^{m\times n}</script> is the weight matrix, and <script type="math/tex">\mathbf{b} \in \mathbf{R^m}</script> is the encoder bias and <script type="math/tex">\mathbf{h} \in \mathbf{R^m}</script> is hidden representation or outputs of hidden units.</p>

<p>For analysis, paper assumes that decoder is linear i.e. <script type="math/tex">\mathbf{W^{T}h}</script> decodes back the encoded hidden representation and loss is squared loss function. Therefore, for learning <script type="math/tex">\mathbf{W,b}</script> parameters of autoencoder; objective function is:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
\begin{split}
J_{AE} &=\mathbb{E_x}[(\mathbf{x-W^Th})^2] \\
&= \mathbb{E_x}[(\mathbf{x-W^Ts(Wx+b)})^2]\\
\end{split}
\end{equation} %]]></script>

<blockquote>
  <p>Now we are interested in sparsity of <script type="math/tex">\mathbf{h}</script>, hidden representation.</p>
</blockquote>

<p>Besides above, paper makes two more assumptions.</p>

<blockquote>
  <p><strong>Assumption 1</strong>: Data is drawn from a distribution <script type="math/tex">\mathbf{x} \sim  X</script> for which <script type="math/tex">\mathbb{E_x}[\mathbf{x}]=0</script> and <script type="math/tex">\mathbb{E_x}[\mathbf{xx^T]=I}</script>, where <script type="math/tex">\mathbf{I}</script> is identity matrix.</p>
</blockquote>

<p>Basically, it assumes that data is whitened which is reasonable for some cases. There is one more assumption from analysis point of view which is needed for the derivation of theorems, we will see that later.</p>

<p>Finally, for a give data sample <script type="math/tex">\mathbf{x}</script>, each hidden unit <script type="math/tex">h_j</script> gets activated if pre-activation unit <script type="math/tex">a_j</script> is greater than <script type="math/tex">\delta</script> threshold:</p>

<script type="math/tex; mode=display">a_j=W_j\mathbf{x}+b_j</script>

<script type="math/tex; mode=display">h_j=s(a_j)</script>

<p>So, the sparsity of <script type="math/tex">\mathbf{h}</script> depends upon the value of pre-activation units (whose value further depend upon the input data samples). If the expected value of pre-activation unit is less than threshold over data distribution then the corresponding hidden unit expected output is  zero.</p>

<blockquote>
  <p>The idea is to somehow show that regularization encourages the expected value of pre-activation unit <script type="math/tex">a_j, \forall j</script>  to reduce on average in autoencoders. This indirectly induces sparsity in <script type="math/tex">\mathbf{h}</script>, hidden representation.</p>
</blockquote>

<p><strong>This should hint us that:</strong> monotonically increasing activation functions would be preferable because we want to decrease hidden unit value as the value of pre-activation unit decreases. On the top of that, if we consider monotonically increasing activation functions with negative saturation at <script type="math/tex">0</script>, i.e. <script type="math/tex">\lim_{a\to-\infty} s(a)=0</script>  then we can make sure that lower average pre-activation value implies higher sparsity. For example, consider <script type="math/tex">tanh</script> function whose range is <script type="math/tex">(-1,1)</script>. If we reduce <script type="math/tex">a</script> below zero, hidden unit output will move away from <script type="math/tex">0</script>.</p>

<p>Let’s focus on analysis now. Assume we want to compute <script type="math/tex">\mathbf{W,b}</script> using gradient descent. Then at <script type="math/tex">t^{th}</script> iteration of updating, we will have:</p>

<script type="math/tex; mode=display">a_j^{t}=W_j^{t}\mathbf{x}+b_j^{t}</script>

<p>where <script type="math/tex">a_j^{t}, W_j^{t}, b_j^{t}</script> are values in <script type="math/tex">t^{th}</script> iteration.</p>

<p>Let regularized objective function of autoencoder is expressed as:</p>

<script type="math/tex; mode=display">J_{RAE}=J_{AE}+\lambda R(\mathbf{W,b})</script>

<p>where <script type="math/tex">R(\mathbf{W,b})</script> is the regularization term and <script type="math/tex">\lambda>0</script>. Simplifying the main theorem of the paper over here:</p>

<blockquote>
  <p><strong>Theorem 1</strong>: For each iteration: <script type="math/tex">% <![CDATA[
\mathbb{E_x}[a_j^{t+1}]<\mathbb{E_x}[a_j^{t}] %]]></script>  holds for <script type="math/tex">\forall j</script> with probability <script type="math/tex">(1-\frac{\sigma^2}{\epsilon^2})</script>, if following conditions are met: <script type="math/tex">\hspace{5em}\lambda \frac{\partial R}{\partial b_j} > 2\epsilon \sqrt{n}  \|W_j\|</script> and encoding activation function, <script type="math/tex">s</script>, first derivative is bounded in <script type="math/tex">[0,1]</script>.</p>
</blockquote>

<p>The above theorem shows that  updating <script type="math/tex">\mathbf{W,b}</script> along the negative gradient of <script type="math/tex">J_{RAE}</script> results in <script type="math/tex">% <![CDATA[
\mathbb{E_x}[a_j^{t+1}]<\mathbb{E_x}[a_j^{t}] %]]></script> with high probability if particular regularization condition is met (plus activation function condition). This means certain regularization terms explicitly encourages sparsity in hidden representation.</p>

<blockquote>
  <p><strong>Corollary 1</strong>: Theorem 1 holds for two special cases: <br />
1)  activation function <script type="math/tex">s</script> is non-decreasing and regularization term has form <script type="math/tex">R=\sum\limits_{j=1}^{m}f(\mathbb{E_x}[h_j])</script> for some monotonically increasing function <script type="math/tex">f.</script><br />
2)  activation function <script type="math/tex">s</script> is convex plus non-decreasing and regularization term has form <script type="math/tex">R=\mathbb{E_x}[\sum\limits_{j=1}^{m}(\frac{\partial h_j}{\partial a_j})^q \|W_j\|^{p}_2]</script> where <script type="math/tex">p</script> is natural and <script type="math/tex">q</script> whole number.</p>
</blockquote>

<p><strong>We are ready to make some remarks about in practice activation functions!</strong></p>

<blockquote>
  <p><strong>ReLu</strong>: It satisfies both corollaries. Hence can be used with any regularized of first form but not the second form (because second derivative does not exist). The advantage of ReLU is
that it enforces hard zeros in the learned representations.</p>
</blockquote>

<blockquote>
  <p><strong>Softplus</strong>: It satisfies both corollaries and encourages sparsity for both suggested regularization form. But does not produce hard zeros.</p>
</blockquote>

<blockquote>
  <p><strong>Sigmoid</strong>: Satisfies only first corollary.  Hence sigmoid is not guaranteed to lead to sparsity when used with second regularizations form.</p>
</blockquote>

<blockquote>
  <p><strong>Maxout and Tanh</strong>: Do not satisfies negative saturation property at <script type="math/tex">0</script> and hence may or may not lead to sparsity.</p>
</blockquote>

<p><strong>Final remarks about about in practice regularized autoencoders!</strong></p>

<ol>
  <li>De-noising Autoencoder (DAE) has regularization of second form.</li>
  <li>Contractive Auto-Encoder (CAE) including higher order has  regularization of second form.</li>
  <li>Marginalized De-noising Auto-Encoder (mDAE) has  regularization of second form.</li>
  <li>Sparse Auto-Encoder (SAE) has regularization of first form.</li>
</ol>

<blockquote>
  <p>Thus, all above autoencoders encourages sparsity theoretically, if chosen with appropriate activation function.</p>
</blockquote>

<p><strong>References</strong>:</p>

<ol>
  <li>Arpit, D., Zhou, Y., Ngo, H., &amp; Govindaraju, V. (2015). Why Regularized Auto-Encoders learn Sparse Representation? ICML2016. <a href="http://arxiv.org/pdf/1505.05561.pdf">[PDF]</a></li>
</ol>


      </div>
      
      
      <div id="disqus_thread"></div>
      <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      
    </article>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    <footer>
      <span><a href="http://localhost:4000">Saurabh Verma</a></span>
      <span><a href="https://github.com/vermaMachineLearning/"><i class="fa fa-github-square"></i></a><a href="https://www.linkedin.com/in/saurabh-verma-10076544"><i class="fa fa-linkedin-square"></i></a><a href="https://www.facebook.com/saurabh.verma.355"><i class="fa fa-facebook-square"></i></a></span>
      <span>&copy; 2017</span>
    </footer>
  </body>
</html>
