<!DOCTYPE html>
<html>
  <head>
    <!-- Saurabh Verma 2016 UMN <https://github.com/vermaMachineLearning> -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="utf-8">
    
    <meta name="description" content="Blog: Machine Learning Equations by Saurabh Verma">
    <title>  Blog: Stability of Learning Algorithms Part 1. › Blog: Machine Learning Equations by Saurabh Verma</title>
    <link rel="canonical" href="http://localhost:4000/tutorials/2017/01/17/Stability-Machine-Learning.html">
    <link href="/main.css" rel="stylesheet" type="text/css">
    <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,200italic,300italic,400italic,600italic,700italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Gentium+Basic:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css' rel='stylesheet' type='text/css'>
    <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Blog: Machine Learning Equations by Saurabh Verma" />
    <script src="//saurabhML.disqus.com/embed.js" async></script>
    
	
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-78615814-1', 'auto');
  ga('send', 'pageview');

</script>

  </head>
  <body>
    <header>
      <h1><a href="/">Blog: Machine Learning Equations by Saurabh Verma</a></h1>
      <nav>
        <ul>
          <li><a href="/">Home</a></li><li><a href="/about.html">About</a></li><li><a href="/archive.html">Archive</a></li>
        </ul>
      </nav>
    </header>
    
    
    <article>
      <header>
        <h2><a href="/tutorials/2017/01/17/Stability-Machine-Learning.html"> Blog: Stability of Learning Algorithms Part 1.</a></h2>
        <p><time datetime="2017-01-17T18:01:00-06:00">Jan 17, 2017</time> • Tutorials</p>
      </header>
      <div>
<p>This is walk-through on how  to derive generalization bounds based on the stability of algorithms. Understanding the proof helps  to extend or modify the results according to your needs. For instance, I had a loss function which was unbounded, and since to apply generalization results your loss function must be bounded, I was stuck. So, this my effort  to state the proof as clear as possible along with the assumptions needed.</p>

<p><strong>Setup</strong>: Let <script type="math/tex">\mathbf{X} \in \mathbb{R}^d, \mathbf{Y} \in \mathbb{R}</script> and <script type="math/tex">S</script> be a training set <script type="math/tex">S=\{\mathbf{z}_1=(\mathbf{x}_1,y_1),\mathbf{z}_2=(\mathbf{x}_2,y_2),...,\mathbf{z}_m=(\mathbf{x}_m,y_m)\}</script>. Let <script type="math/tex">A_S</script> be a symmetric learning algorithm i.e.  does not depend on the order of the data points in the training set. We define the following two more notations as follows:</p>

<p>Removing <script type="math/tex">i^{th}</script> data point in the set <script type="math/tex">S</script>.</p>

<script type="math/tex; mode=display">S^{\backslash i}=\{\mathbf{z}_1,....,\mathbf{z}_{i-1},\mathbf{z}_{i+1},.....,\mathbf{z}_m \}</script>

<p>Replacing <script type="math/tex">i^{th}</script> data point in the set <script type="math/tex">S</script> by <script type="math/tex">\mathbf{z}_{i}^{'}</script>.</p>

<script type="math/tex; mode=display">S^{i}=\{\mathbf{z}_1,....,\mathbf{z}_{i-1},\mathbf{z}_{i}^{'},\mathbf{z}_{i+1},.....,\mathbf{z}_m \}</script>

<p>Let <script type="math/tex">D</script> be an unknown distribution from which <script type="math/tex">\mathbf{z}_1,....,\mathbf{z}_m</script> data points are sampled to form a training set <script type="math/tex">S</script>. Here, we assume all samples (including the replacement sample) are i.i.d. unless mentioned otherwise. Let <script type="math/tex">\mathbf{E}_S[f]</script> denotes the expectation of the function <script type="math/tex">f</script> when  <script type="math/tex">m</script>  samples are drawn from the distribution <script type="math/tex">D</script> to form <script type="math/tex">S</script>. Similarly, let <script type="math/tex">\mathbf{E}_z[f]</script> denotes the expectation of the function <script type="math/tex">f</script> when  <script type="math/tex">\mathbf{z}</script> is sampled  according to the distribution <script type="math/tex">D</script>.</p>

<p>We define the generalization error or risk <script type="math/tex">R(A_S)</script> as follows:</p>

<script type="math/tex; mode=display">R(A_S)=\mathbf{E}_z[\ell(A_S,\mathbf{z})]=\int \ell(A_S,\mathbf{z}) p(\mathbf{z}) d\mathbf{z}</script>

<p>Empirical error <script type="math/tex">R_{emp}(A_S)</script> is defined as follows:</p>

<script type="math/tex; mode=display">R_{emp}(A_S):=\frac{1}{m}\sum\limits_{j=1}^{m}\ell(A_S,\mathbf{z}_j)</script>

<script type="math/tex; mode=display">\implies R_{emp}(A_{S^{  i}})=\frac{1}{m}\sum\limits_{j=1, j \neq i}^{m}\ell(A_{S^{ i}},\mathbf{z}_j)+\frac{1}{m}\ell(A_{S^{ i}},\mathbf{z}_i^{'})</script>

<script type="math/tex; mode=display">R_{emp}(A_{S^{\backslash i}}):=\frac{1}{m}\sum\limits_{j=1, j \neq i}^{m}\ell(A_{S^{\backslash i}},\mathbf{z}_j)</script>

<p><strong>Generalization Bounds based on Stability of Learning Algorithms</strong>:</p>

<blockquote>
  <p>Let’s assume that our algorithm <script type="math/tex">A_S</script> has uniform stability <script type="math/tex">\beta</script>, i.e.  it satisfies <script type="math/tex">\forall i\in\{1,m\}</script>,</p>

  <script type="math/tex; mode=display">\underset{S,z}{\sup}|\ell(A_S,\mathbf{z}) -\ell(A_{S^{\backslash i}},\mathbf{z})| \leq \beta</script>
</blockquote>

<p>To derive generalization bounds for uniform stable algorithms, we are going to only use McDiarmid’s inequality. Let <script type="math/tex">\mathbf{X}</script> be some set and <script type="math/tex">f:\mathbf{X}^{m} \rightarrow R</script>, then inequality is given as (more detail <a href="http://web.eecs.umich.edu/~cscott/past_courses/eecs598w14/notes/09_bounded_difference.pdf">here</a>),</p>

<blockquote>
  <script type="math/tex; mode=display">if \underset{x_1,..,x_i,..,x_m,x_i^{'}}{\sup}|f(x_1,..,x_i,..,x_m)-f(x_1,..,x_i^{'},..,x_m)| \leq c_i</script>

  <script type="math/tex; mode=display">=\underset{x_1,..,x_i,..,x_m,x_i^{'}}{\sup}|f_S-f_{S^{i}}| \leq c_i \hspace{1em},\forall i</script>

  <script type="math/tex; mode=display">\implies P\Big( f(S)-\mathbf{E}_S[f(S)] \geq \epsilon \Big) \leq e^{-\frac{2 \epsilon^2}{\sum_{i=1}^{m}c_i^2}}</script>
</blockquote>

<p>Strategy is to bound <script type="math/tex">\vert f_S-f_{S^{i}} \vert</script> using <script type="math/tex">\vert f_S-f_{S^{\backslash i}} \vert</script>, <script type="math/tex">\vert f_{S^{i}}-f_{S^{\backslash i}} \vert</script>.  We will derive some lemmas that would be helpful to compute variables needed for applying McDiarmid’s inequality.</p>

<p>Since, samples are i.i.d., we have,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
\begin{split}
\mathbf{E}_{S}[\ell(A_S,\mathbf{z})] &=\int \ell\big(A(\mathbf{z}_1,...,\mathbf{z}_m),\mathbf{z}\big)p(\mathbf{z}_1,...,\mathbf{z}_m) d\mathbf{z}_1...d\mathbf{z}_m \\
&=\int \ell\big(A(\mathbf{z}_1,...,\mathbf{z}_m),\mathbf{z}\big)p(\mathbf{z}_1)...p(\mathbf{z}_m)  d\mathbf{z}_1...d\mathbf{z}_m \\
\end{split}
\end{equation} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
\begin{split}
\mathbf{E}_{S}[\ell(A_S,\mathbf{z}_j)] &=\int \ell\big(A(\mathbf{z}_1,..,\mathbf{z}_j,..,\mathbf{z}_m),\mathbf{z}_j\big)p(\mathbf{z}_1,..,\mathbf{z}_j,..,\mathbf{z}_m) d\mathbf{z}_1...d\mathbf{z}_m \\
& = \int \ell\big(A(\mathbf{z}_1,..,\mathbf{z}_j,..,\mathbf{z}_m),\mathbf{z}_j\big)p(\mathbf{z}_1)..p(\mathbf{z}_j)..p(\mathbf{z}_m) d\mathbf{z}_1...d\mathbf{z}_m \\
& = \int \ell\big(A(\mathbf{z}_1,..,\mathbf{z}_i^{'},..,\mathbf{z}_m),\mathbf{z}_i^{'}\big)p(\mathbf{z}_1)..p(\mathbf{z}_i^{'})..p(\mathbf{z}_m) d\mathbf{z}_1..d\mathbf{z}_i^{'}..d\mathbf{z}_m \\
& = \int \ell\big(A(\mathbf{z}_1,..,\mathbf{z}_i^{'},..,\mathbf{z}_m),\mathbf{z}_i^{'}\big)p(\mathbf{z}_1,..,\mathbf{z}_i^{'},..,\mathbf{z}_m) d\mathbf{z}_1..d\mathbf{z}_i^{'}..d\mathbf{z}_m  \int p(\mathbf{z}_i) d\mathbf{z}_i\\
& = \int \ell\big(A(\mathbf{z}_1,..,\mathbf{z}_i^{'},..,\mathbf{z}_m),\mathbf{z}_i^{'}\big)p(\mathbf{z}_1,..,\mathbf{z}_i,\mathbf{z}_i^{'},..,\mathbf{z}_m) d\mathbf{z}_1...d\mathbf{z}_m d\mathbf{z}_i^{'}\\
&=\mathbf{E}_{S,z_{i}^{'}}[\ell(A_{S^{i}},\mathbf{z}_i^{'})]
\end{split}
\end{equation} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
\begin{split}
\mathbf{E}_S[R(A_S)-R_{emp}(A_S)] &= \mathbf{E}_{S}[\mathbf{E}_z[\ell(A_S,\mathbf{z})]]-\frac{1}{m}\sum\limits_{j=1}^{m}\mathbf{E}_{S}[\ell(A_S,\mathbf{z}_j)] \\
&= \mathbf{E}_{S}[\mathbf{E}_z[\ell(A_S,\mathbf{z})]]-\mathbf{E}_{S}[\ell(A_S,\mathbf{z}_j)] \\
%& =\mathbf{E}_{S}[\mathbf{E}_{z_{i}^{'}}[\ell(A_S,\mathbf{z}_{i}^{'})]] -    \mathbf{E}_{z_{i}^{'}}[\mathbf{E}_{S}[\ell(A_{S^{i}},\mathbf{z}_i^{'})]] \\
& =\mathbf{E}_{S,z_{i}^{'}}[\ell(A_S,\mathbf{z}_{i}^{'})]]- \mathbf{E}_{S,z_{i}^{'}}[\ell(A_{S^{i}},\mathbf{z}_i^{'})]\\
& =\mathbf{E}_{S,z_{i}^{'}}[\ell(A_S,\mathbf{z}_{i}^{'})-\ell(A_{S^{i}},\mathbf{z}_{i}^{'})] \\
\end{split}
\end{equation} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
\begin{split}
|R(A_S)-R(A_{S^{\backslash i}})|&=  |\mathbf{E}_z[\ell(A_S,\mathbf{z})]-\mathbf{E}_z[\ell(A_{S^{\backslash i}},\mathbf{z})]| \\
& =	|\mathbf{E}_z[\ell(A_S,\mathbf{z}) - \ell(A_{S^{\backslash i}},\mathbf{z})] |\\
& \leq \mathbf{E}_z[|\ell(A_S,\mathbf{z})-\ell(A_{S^{\backslash i}},\mathbf{z})|] \\
& \leq \mathbf{E}_z[\beta]=\beta \\
|R(A_{S^{i}})-R(A_{S^{\backslash i}})|& \leq  \mathbf{E}_z[|\ell(A_{S^{i}},\mathbf{z})-\ell(A_{S^{\backslash i}},\mathbf{z})|] \\
& \leq \mathbf{E}_z[\beta]=\beta \\
\end{split}
\end{equation} %]]></script>

<!---
$$\begin{equation}
\begin{split}
|R_{emp}(A_S)-R_{emp}(A_{S^{\backslash i}})|&= \Big|\frac{1}{m}\sum\limits_{j=1}^{m}\ell(A_S,\mathbf{z}_j)-\frac{1}{m}\sum\limits_{j=1,j \neq i}^{m}\ell(A_{S^{\backslash i}},\mathbf{z}_j) \Big|  \\
& \leq \Big| \frac{1}{m}\sum\limits_{j=1,j \neq i}^{m} (\ell(A_S,\mathbf{z}_j)-\ell(A_{S^{\backslash i}},\mathbf{z}_j)) \Big|+\Big| \frac{1}{m}\ell(A_S,\mathbf{z}_i) \Big| \\
& \leq \frac{(m-1)}{m}\beta  +\frac{M}{m} \\
& \leq \beta  +\frac{M}{m} \\
\end{split}
\end{equation}$$
-->

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
\begin{split}
|R(A_S)-R(A_{S^{i}})|& \leq|R(A_S)-R(A_{S^{\backslash i}})|+|R(A_{S^{\backslash i}}) - R(A_{S^{i}}) |\\
& \leq 2\beta \\
\end{split}
\end{equation} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
\begin{split}
|R_{emp}(A_S)-R_{emp}(A_{S^{i}})| & \leq |\frac{1}{m}\sum\limits_{j=1,j \neq i}^{m} (\ell(A_S,\mathbf{z}_j)-\ell(A_{S^{i}},\mathbf{z}_j))|+|\frac{1}{m} (\ell(A_S,\mathbf{z}_i)-\ell(A_{S^{i}},\mathbf{z}_i^{'})) |\\
& \leq  |\frac{1}{m}\sum\limits_{j=1,j \neq i}^{m} (\ell(A_S,\mathbf{z}_j)-\ell(A_{S^{\backslash i}},\mathbf{z}_j))|+ |\frac{1}{m}\sum\limits_{j=1,j \neq i}^{m} (\ell(A_{S^{i}},\mathbf{z}_j)-\ell(A_{S^{\backslash i}},\mathbf{z}_j))|  + \\
& |\frac{1}{m} (\ell(A_S,\mathbf{z}_i)-\ell(A_{S^{i}},\mathbf{z}_i^{'})) |\\
& \leq  2\frac{(m-1)}{m}\beta +\frac{M}{m} \\
& \leq   2\beta +\frac{M}{m} \\
\end{split}
\end{equation} %]]></script>

<blockquote>
  <p>Note: <script type="math/tex">(\ell(A_S,\mathbf{z}_i)-\ell(A_{S^{i}},\mathbf{z}_i^{'}))</script> introduces <script type="math/tex">M</script> (bound on loss) in the equation. If your loss is <strong>unbounded</strong> then you may be able to bound <script type="math/tex">(\ell(A_S,\mathbf{z}_i)-\ell(A_{S^{i}},\mathbf{z}_i^{'}))</script> and just replace <script type="math/tex">M</script> by it, in the generalization bound.</p>
</blockquote>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
\begin{split}
|\big(R(A_S)-R_{emp}(A_{S})\big) -\big(R(A_{S^{i}})-R_{emp}(A_{S^{i}})\big)|& \leq |R(A_S)-R(A_{S^{i}})| + |R_{emp}(A_S)-R_{emp}(A_{S^{i}})|\\
&\leq 2\beta+2\beta+\frac{M}{m} \\
& =4\beta+\frac{M}{m} \\
\end{split}
\end{equation} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
\begin{split}
\mathbf{E}_{S}[R(A_S)-R_{emp}(A_S)] &= \mathbf{E}_{S,z_{i}^{'}}[\ell(A_S,\mathbf{z}_{i}^{'})-\ell(A_{S^{i}},\mathbf{z}_{i}^{'})] \\
& \leq \mathbf{E}_{S,z_{i}^{'}}[|\ell(A_S,\mathbf{z}_{i}^{'})-\ell(A_{S^{i}},\mathbf{z}_{i}^{'})|]\\
& \leq \mathbf{E}_{S,z_{i}^{'}}[|\ell(A_S,\mathbf{z}_{i}^{'})-\ell(A_{S^{\backslash i}},\mathbf{z}_{i}^{'})| + |\ell(A_{S^{i}},\mathbf{z}_{i}^{'})-\ell(A_{S^{\backslash i}},\mathbf{z}_{i}^{'})|]\\
& \leq 2\beta \\
\end{split}
\end{equation} %]]></script>

<blockquote>
  <p>Applying McDiarmid’s inequality to derive generalization bounds for uniform stable algorithms:</p>

  <center>$$ \mathbf{P}\Bigg( \Big(R(A_S)-R_{emp}(A_S)\Big)  - 2\beta \geq   \epsilon \Bigg)  \leq \underbrace{e^{-\frac{2\epsilon^2}{m(4\beta+\frac{M}{m})^2}}}_{\delta} $$
$$ \implies    \mathbf{P}\Bigg( \Big(R(A_S)-R_{emp}(A_S)\Big) \leq  2\beta +  (4m\beta+M)\sqrt{\frac{\log \frac{1}{\delta}}{2m}} \Bigg) \geq 1-\delta $$</center>
</blockquote>


      </div>
      
      
      <div id="disqus_thread"></div>
      <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      
    </article>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({ TeX: { extensions: ["color.js"] }});
</script>
    <footer>
      <span><a href="http://localhost:4000">Saurabh Verma</a></span>
      <span><a href="https://github.com/vermaMachineLearning/"><i class="fa fa-github-square"></i></a><a href="https://www.linkedin.com/in/saurabh-verma-10076544"><i class="fa fa-linkedin-square"></i></a><a href="https://www.facebook.com/saurabh.verma.355"><i class="fa fa-facebook-square"></i></a></span>
      <span>&copy; 2017</span>
    </footer>
  </body>
</html>
